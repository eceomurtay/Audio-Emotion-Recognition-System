{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import librosa as lr\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./Audio\"\n",
    "audio_files = glob(data_dir + \"/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "Emotion = []\n",
    "Emotional_Intensity = []\n",
    "Statement = []\n",
    "Statement_Text = []\n",
    "Repetition = []\n",
    "Actor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating grand truth target values for training data\n",
    "for i in range(len(audio_files)):\n",
    "    temp = audio_files[i][audio_files[i].index(\"\\\\\")+1:audio_files[0].index(\".wav\")].split(\"-\")\n",
    "    \n",
    "    # creating Emotion\n",
    "    if temp[2] == \"01\":\n",
    "        Emotion.append(1)\n",
    "    if temp[2] == \"02\":\n",
    "        Emotion.append(2)\n",
    "    if temp[2] == \"03\":\n",
    "        Emotion.append(3)\n",
    "    if temp[2] == \"04\":\n",
    "        Emotion.append(4)\n",
    "    if temp[2] == \"05\":\n",
    "        Emotion.append(5)\n",
    "    if temp[2] == \"06\":\n",
    "        Emotion.append(6)\n",
    "    if temp[2] == \"07\":\n",
    "        Emotion.append(7)\n",
    "    if temp[2] == \"08\":\n",
    "        Emotion.append(8)\n",
    "\n",
    "   ############################\n",
    "\n",
    "    # creating Emotinal_Intensity\n",
    "    if temp[3] == \"01\":\n",
    "        Emotional_Intensity.append(1)\n",
    "    if temp[3] == \"02\":\n",
    "        Emotional_Intensity.append(2)\n",
    "        \n",
    "   #############################\n",
    "\n",
    "    # creating Statement\n",
    "    if temp[4] == \"01\":\n",
    "        Statement.append(1)\n",
    "        Statement_Text.append(\"Kids are talking by the door\")\n",
    "    if temp[4] == \"02\":\n",
    "        Statement.append(2)\n",
    "        Statement_Text.append(\"Dogs are sitting by the door\")\n",
    "        \n",
    "    ############################\n",
    "    \n",
    "    # creating Repetition\n",
    "    if temp[5] == \"01\":\n",
    "        Repetition.append(1)\n",
    "    if temp[5] == \"02\":\n",
    "        Repetition.append(2)\n",
    "        \n",
    "    ###########################\n",
    "    \n",
    "    # creating actor gender\n",
    "    if int(temp[6])%2 == 0:   # even --> female\n",
    "        Actor.append(1)\n",
    "    if int(temp[6])%2 == 1:   # odd --> male\n",
    "        Actor.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Emotion\"] = Emotion\n",
    "data[\"Emotional_Intensity\"] = Emotional_Intensity\n",
    "data[\"Statement\"] = Statement\n",
    "data[\"Statement_Text\"] = Statement_Text\n",
    "data[\"Repetition\"] = Repetition\n",
    "data[\"Actor_Gender\"] = Actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting mfcc features from audios\n",
    "mfcc1 = []\n",
    "for i in range(0,len(audio_files)):\n",
    "    \n",
    "    y, sr = lr.load(audio_files[i],res_type=\"kaiser_fast\",duration=3,offset=0.5)\n",
    "    sr=np.array(sr)\n",
    "    mfcc=(lr.feature.mfcc(y=y,hop_length=256,n_mfcc=13))\n",
    "    #This line controls audios lenght if it is shorter than the trashold algoritm pads mfcc feature with 0\n",
    "    if (259 > mfcc.shape[1]):\n",
    "        pad_width = 259 - mfcc.shape[1]\n",
    "        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        mfcc1.append(mfcc)\n",
    "    else:\n",
    "        mfcc1.append(mfcc)\n",
    "    \n",
    "mfccTarget1 = pd.DataFrame()\n",
    "mfccTarget1[\"mfcc\"] = mfcc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1008 samples, validate on 432 samples\n",
      "Epoch 1/100\n",
      "1008/1008 [==============================] - 3s 3ms/step - loss: 20.2733 - accuracy: 0.1359 - val_loss: 6.7728 - val_accuracy: 0.2060\n",
      "Epoch 2/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 3.2882 - accuracy: 0.1925 - val_loss: 2.2677 - val_accuracy: 0.1852\n",
      "Epoch 3/100\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.9151 - accuracy: 0.3046 - val_loss: 1.7315 - val_accuracy: 0.3310\n",
      "Epoch 4/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 1.7357 - accuracy: 0.3631 - val_loss: 1.6710 - val_accuracy: 0.3519\n",
      "Epoch 5/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 1.5787 - accuracy: 0.4226 - val_loss: 1.7242 - val_accuracy: 0.3356\n",
      "Epoch 6/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 1.4934 - accuracy: 0.4355 - val_loss: 1.5266 - val_accuracy: 0.4329\n",
      "Epoch 7/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 1.3552 - accuracy: 0.4940 - val_loss: 1.4893 - val_accuracy: 0.4491\n",
      "Epoch 8/100\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.2860 - accuracy: 0.5228 - val_loss: 1.5109 - val_accuracy: 0.4398\n",
      "Epoch 9/100\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 1.1665 - accuracy: 0.5665 - val_loss: 1.4999 - val_accuracy: 0.4699\n",
      "Epoch 10/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 1.0927 - accuracy: 0.5903 - val_loss: 1.4080 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.9626 - accuracy: 0.6448 - val_loss: 1.4460 - val_accuracy: 0.4838\n",
      "Epoch 12/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.8137 - accuracy: 0.7004 - val_loss: 1.3372 - val_accuracy: 0.5023\n",
      "Epoch 13/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.7157 - accuracy: 0.7500 - val_loss: 1.6955 - val_accuracy: 0.4769\n",
      "Epoch 14/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.7076 - accuracy: 0.7431 - val_loss: 1.2927 - val_accuracy: 0.5324\n",
      "Epoch 15/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.6645 - accuracy: 0.7530 - val_loss: 1.3576 - val_accuracy: 0.5648\n",
      "Epoch 16/100\n",
      "1008/1008 [==============================] - 1s 938us/step - loss: 0.4850 - accuracy: 0.8234 - val_loss: 1.4034 - val_accuracy: 0.5463\n",
      "Epoch 17/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.4631 - accuracy: 0.8264 - val_loss: 1.6429 - val_accuracy: 0.4954\n",
      "Epoch 18/100\n",
      "1008/1008 [==============================] - 1s 928us/step - loss: 0.5007 - accuracy: 0.8234 - val_loss: 1.8187 - val_accuracy: 0.5185\n",
      "Epoch 19/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.4226 - accuracy: 0.8442 - val_loss: 1.6678 - val_accuracy: 0.5069\n",
      "Epoch 20/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.3427 - accuracy: 0.8810 - val_loss: 1.4807 - val_accuracy: 0.5880\n",
      "Epoch 21/100\n",
      "1008/1008 [==============================] - 1s 951us/step - loss: 0.2903 - accuracy: 0.8869 - val_loss: 1.7564 - val_accuracy: 0.5417\n",
      "Epoch 22/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.2508 - accuracy: 0.9097 - val_loss: 1.5511 - val_accuracy: 0.5718\n",
      "Epoch 23/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1910 - accuracy: 0.9375 - val_loss: 1.6543 - val_accuracy: 0.5625\n",
      "Epoch 24/100\n",
      "1008/1008 [==============================] - 1s 970us/step - loss: 0.2186 - accuracy: 0.9206 - val_loss: 1.9369 - val_accuracy: 0.5394\n",
      "Epoch 25/100\n",
      "1008/1008 [==============================] - 1s 999us/step - loss: 0.3155 - accuracy: 0.8879 - val_loss: 1.8662 - val_accuracy: 0.5347\n",
      "Epoch 26/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1638 - accuracy: 0.9454 - val_loss: 1.4227 - val_accuracy: 0.6111\n",
      "Epoch 27/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1352 - accuracy: 0.9573 - val_loss: 2.0346 - val_accuracy: 0.5579\n",
      "Epoch 28/100\n",
      "1008/1008 [==============================] - 1s 932us/step - loss: 0.1216 - accuracy: 0.9633 - val_loss: 1.5629 - val_accuracy: 0.5880\n",
      "Epoch 29/100\n",
      "1008/1008 [==============================] - 1s 980us/step - loss: 0.1111 - accuracy: 0.9633 - val_loss: 1.9582 - val_accuracy: 0.5648\n",
      "Epoch 30/100\n",
      "1008/1008 [==============================] - 1s 900us/step - loss: 0.3629 - accuracy: 0.8671 - val_loss: 1.9778 - val_accuracy: 0.5417\n",
      "Epoch 31/100\n",
      "1008/1008 [==============================] - 1s 946us/step - loss: 0.2352 - accuracy: 0.9147 - val_loss: 1.9011 - val_accuracy: 0.5509\n",
      "Epoch 32/100\n",
      "1008/1008 [==============================] - 1s 901us/step - loss: 0.1163 - accuracy: 0.9663 - val_loss: 1.8656 - val_accuracy: 0.5787\n",
      "Epoch 33/100\n",
      "1008/1008 [==============================] - 1s 878us/step - loss: 0.0785 - accuracy: 0.9752 - val_loss: 1.9082 - val_accuracy: 0.5949\n",
      "Epoch 34/100\n",
      "1008/1008 [==============================] - 1s 941us/step - loss: 0.0539 - accuracy: 0.9861 - val_loss: 1.8640 - val_accuracy: 0.6111\n",
      "Epoch 35/100\n",
      "1008/1008 [==============================] - 1s 942us/step - loss: 0.0733 - accuracy: 0.9762 - val_loss: 1.9150 - val_accuracy: 0.5972\n",
      "Epoch 36/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0743 - accuracy: 0.9732 - val_loss: 1.9414 - val_accuracy: 0.5880\n",
      "Epoch 37/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1470 - accuracy: 0.9444 - val_loss: 1.9110 - val_accuracy: 0.6065\n",
      "Epoch 38/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1332 - accuracy: 0.9613 - val_loss: 2.1535 - val_accuracy: 0.5741\n",
      "Epoch 39/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9464 - val_loss: 2.1437 - val_accuracy: 0.5764\n",
      "Epoch 40/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1292 - accuracy: 0.9583 - val_loss: 1.7931 - val_accuracy: 0.6111\n",
      "Epoch 41/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0801 - accuracy: 0.9732 - val_loss: 2.0863 - val_accuracy: 0.6042\n",
      "Epoch 42/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0796 - accuracy: 0.9742 - val_loss: 2.1192 - val_accuracy: 0.5949\n",
      "Epoch 43/100\n",
      "1008/1008 [==============================] - 1s 992us/step - loss: 0.1041 - accuracy: 0.9623 - val_loss: 2.1354 - val_accuracy: 0.6042\n",
      "Epoch 44/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1938 - accuracy: 0.9415 - val_loss: 2.4403 - val_accuracy: 0.5278\n",
      "Epoch 45/100\n",
      "1008/1008 [==============================] - 1s 955us/step - loss: 0.1031 - accuracy: 0.9623 - val_loss: 2.1171 - val_accuracy: 0.5880\n",
      "Epoch 46/100\n",
      "1008/1008 [==============================] - 1s 954us/step - loss: 0.1551 - accuracy: 0.9464 - val_loss: 2.1216 - val_accuracy: 0.5972\n",
      "Epoch 47/100\n",
      "1008/1008 [==============================] - 1s 998us/step - loss: 0.1189 - accuracy: 0.9623 - val_loss: 2.3846 - val_accuracy: 0.5926\n",
      "Epoch 48/100\n",
      "1008/1008 [==============================] - 1s 945us/step - loss: 0.1254 - accuracy: 0.9554 - val_loss: 2.2560 - val_accuracy: 0.5579\n",
      "Epoch 49/100\n",
      "1008/1008 [==============================] - 1s 943us/step - loss: 0.1039 - accuracy: 0.9623 - val_loss: 2.2196 - val_accuracy: 0.5903\n",
      "Epoch 50/100\n",
      "1008/1008 [==============================] - 1s 965us/step - loss: 0.1474 - accuracy: 0.9504 - val_loss: 2.2902 - val_accuracy: 0.5880\n",
      "Epoch 51/100\n",
      "1008/1008 [==============================] - 1s 971us/step - loss: 0.1296 - accuracy: 0.9544 - val_loss: 2.3960 - val_accuracy: 0.5787\n",
      "Epoch 52/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1638 - accuracy: 0.9494 - val_loss: 2.6465 - val_accuracy: 0.5463\n",
      "Epoch 53/100\n",
      "1008/1008 [==============================] - 1s 996us/step - loss: 0.1382 - accuracy: 0.9554 - val_loss: 2.2881 - val_accuracy: 0.6065\n",
      "Epoch 54/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.2312 - accuracy: 0.9256 - val_loss: 2.3418 - val_accuracy: 0.5440\n",
      "Epoch 55/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1620 - accuracy: 0.9484 - val_loss: 2.4725 - val_accuracy: 0.5694\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1020 - accuracy: 0.9593 - val_loss: 2.2871 - val_accuracy: 0.5741\n",
      "Epoch 57/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1036 - accuracy: 0.9583 - val_loss: 2.4123 - val_accuracy: 0.5833\n",
      "Epoch 58/100\n",
      "1008/1008 [==============================] - 1s 993us/step - loss: 0.1823 - accuracy: 0.9484 - val_loss: 2.1284 - val_accuracy: 0.6157\n",
      "Epoch 59/100\n",
      "1008/1008 [==============================] - 1s 971us/step - loss: 0.0697 - accuracy: 0.9772 - val_loss: 2.2766 - val_accuracy: 0.5903\n",
      "Epoch 60/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 2.1896 - val_accuracy: 0.6019\n",
      "Epoch 61/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.9762 - val_loss: 2.2320 - val_accuracy: 0.6134\n",
      "Epoch 62/100\n",
      "1008/1008 [==============================] - 1s 978us/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 2.0876 - val_accuracy: 0.5949\n",
      "Epoch 63/100\n",
      "1008/1008 [==============================] - 1s 967us/step - loss: 0.0261 - accuracy: 0.9901 - val_loss: 2.4961 - val_accuracy: 0.5926\n",
      "Epoch 64/100\n",
      "1008/1008 [==============================] - 1s 979us/step - loss: 0.0361 - accuracy: 0.9881 - val_loss: 2.5345 - val_accuracy: 0.5903\n",
      "Epoch 65/100\n",
      "1008/1008 [==============================] - 1s 981us/step - loss: 0.0572 - accuracy: 0.9881 - val_loss: 2.4226 - val_accuracy: 0.5833\n",
      "Epoch 66/100\n",
      "1008/1008 [==============================] - 1s 982us/step - loss: 0.0378 - accuracy: 0.9841 - val_loss: 2.4183 - val_accuracy: 0.5810\n",
      "Epoch 67/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 2.3939 - val_accuracy: 0.6088\n",
      "Epoch 68/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9970 - val_loss: 2.2868 - val_accuracy: 0.6134\n",
      "Epoch 69/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 2.5984 - val_accuracy: 0.5856\n",
      "Epoch 70/100\n",
      "1008/1008 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.6157\n",
      "Epoch 71/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.3527 - val_accuracy: 0.6204\n",
      "Epoch 72/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 2.4258 - val_accuracy: 0.6134\n",
      "Epoch 73/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0139 - accuracy: 0.9940 - val_loss: 2.5394 - val_accuracy: 0.5949\n",
      "Epoch 74/100\n",
      "1008/1008 [==============================] - 1s 977us/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 2.6850 - val_accuracy: 0.5995\n",
      "Epoch 75/100\n",
      "1008/1008 [==============================] - 1s 942us/step - loss: 0.0073 - accuracy: 0.9990 - val_loss: 2.5506 - val_accuracy: 0.5833\n",
      "Epoch 76/100\n",
      "1008/1008 [==============================] - 1s 956us/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 2.4652 - val_accuracy: 0.6204\n",
      "Epoch 77/100\n",
      "1008/1008 [==============================] - 1s 941us/step - loss: 0.0176 - accuracy: 0.9921 - val_loss: 2.9346 - val_accuracy: 0.5787\n",
      "Epoch 78/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 2.6001 - val_accuracy: 0.6250\n",
      "Epoch 79/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0076 - accuracy: 0.9960 - val_loss: 2.6505 - val_accuracy: 0.6181\n",
      "Epoch 80/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0306 - accuracy: 0.9931 - val_loss: 2.5738 - val_accuracy: 0.5949\n",
      "Epoch 81/100\n",
      "1008/1008 [==============================] - 1s 949us/step - loss: 0.0936 - accuracy: 0.9692 - val_loss: 2.5042 - val_accuracy: 0.5625\n",
      "Epoch 82/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1265 - accuracy: 0.9623 - val_loss: 2.8535 - val_accuracy: 0.5648\n",
      "Epoch 83/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.9167 - val_loss: 3.9140 - val_accuracy: 0.5093\n",
      "Epoch 84/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.6063 - accuracy: 0.8393 - val_loss: 2.4421 - val_accuracy: 0.5139\n",
      "Epoch 85/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.3870 - accuracy: 0.8849 - val_loss: 2.4460 - val_accuracy: 0.5532\n",
      "Epoch 86/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1884 - accuracy: 0.9315 - val_loss: 2.6988 - val_accuracy: 0.5741\n",
      "Epoch 87/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0864 - accuracy: 0.9692 - val_loss: 2.3546 - val_accuracy: 0.5880\n",
      "Epoch 88/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0750 - accuracy: 0.9702 - val_loss: 2.5013 - val_accuracy: 0.5556\n",
      "Epoch 89/100\n",
      "1008/1008 [==============================] - 1s 967us/step - loss: 0.0573 - accuracy: 0.9861 - val_loss: 2.6211 - val_accuracy: 0.6065\n",
      "Epoch 90/100\n",
      "1008/1008 [==============================] - 1s 989us/step - loss: 0.0720 - accuracy: 0.9762 - val_loss: 2.5599 - val_accuracy: 0.5880\n",
      "Epoch 91/100\n",
      "1008/1008 [==============================] - 1s 971us/step - loss: 0.0808 - accuracy: 0.9742 - val_loss: 2.4213 - val_accuracy: 0.5671\n",
      "Epoch 92/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.1316 - accuracy: 0.9524 - val_loss: 2.5581 - val_accuracy: 0.5556\n",
      "Epoch 93/100\n",
      "1008/1008 [==============================] - 1s 997us/step - loss: 0.0639 - accuracy: 0.9812 - val_loss: 2.9420 - val_accuracy: 0.5671\n",
      "Epoch 94/100\n",
      "1008/1008 [==============================] - 1s 947us/step - loss: 0.0321 - accuracy: 0.9901 - val_loss: 2.5176 - val_accuracy: 0.6250\n",
      "Epoch 95/100\n",
      "1008/1008 [==============================] - 1s 950us/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 2.9276 - val_accuracy: 0.5718\n",
      "Epoch 96/100\n",
      "1008/1008 [==============================] - 1s 980us/step - loss: 0.0528 - accuracy: 0.9821 - val_loss: 2.8396 - val_accuracy: 0.5949\n",
      "Epoch 97/100\n",
      "1008/1008 [==============================] - 1s 983us/step - loss: 0.0320 - accuracy: 0.9881 - val_loss: 2.8138 - val_accuracy: 0.5995\n",
      "Epoch 98/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 2.9085 - val_accuracy: 0.6134\n",
      "Epoch 99/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 2.7194 - val_accuracy: 0.6157\n",
      "Epoch 100/100\n",
      "1008/1008 [==============================] - 1s 1ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 3.0359 - val_accuracy: 0.6042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28146fc1d48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN model with the best accuracies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten,Dropout,MaxPooling1D,Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(mfccTarget1[\"mfcc\"].tolist()),data[\"Emotion\"].to_numpy(), test_size=0.30, random_state=42,shuffle=True)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 5,padding='same', input_shape=(13,259))) #1\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same')) #2\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same')) #3\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same')) #6\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(9)) #7\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
